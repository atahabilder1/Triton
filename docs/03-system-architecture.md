# Chapter 3: System Architecture

[â† Back to Index](README.md) | [Previous: Quick Start](02-quick-start.md) | [Next: GAT Explained â†’](04-gat-explained.md)

---

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [High-Level Architecture](#high-level-architecture)
- [Component Details](#component-details)
- [Data Flow](#data-flow)
- [Why This Architecture?](#why-this-architecture)
- [Comparison with Existing Tools](#comparison-with-existing-tools)

---

## Overview

Triton uses a **multi-modal, multi-stage architecture** designed to detect smart contract vulnerabilities from three complementary perspectives:

1. **Static View** - Code structure (GAT on PDG)
2. **Dynamic View** - Execution behavior (LSTM on traces)
3. **Semantic View** - Code meaning (GraphCodeBERT on source)

These are combined using an **intelligent fusion module** and refined iteratively by an **RL-based orchestrator**.

---

## High-Level Architecture

### Visual Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          TRITON SYSTEM ARCHITECTURE                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ Smart Contract   â”‚
                           â”‚  (Solidity)      â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
                    â†“               â†“               â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Parse AST  â”‚  â”‚Build Traces â”‚  â”‚  Tokenize    â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                â”‚                 â”‚
                â†“                â†“                 â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Build PDG  â”‚  â”‚  Normalize  â”‚  â”‚   Embed      â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                â”‚                 â”‚
                â”‚                â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ENCODERS     â”‚                â”‚                 â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               â†“                â†“                 â†“               â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚      â”‚    GAT       â”‚  â”‚    LSTM      â”‚  â”‚GraphCodeBERT â”‚      â”‚
â”‚      â”‚ (3 layers)   â”‚  â”‚ (2 layers)   â”‚  â”‚  (12 layers) â”‚      â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚             â”‚                  â”‚                 â”‚               â”‚
â”‚             â†“                  â†“                 â†“               â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚      â”‚Static        â”‚  â”‚Dynamic       â”‚  â”‚Semantic      â”‚      â”‚
â”‚      â”‚Features      â”‚  â”‚Features      â”‚  â”‚Features      â”‚      â”‚
â”‚      â”‚(768-dim)     â”‚  â”‚(512-dim)     â”‚  â”‚(768-dim)     â”‚      â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                  â”‚                 â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FUSION                        â†“                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                      â”‚ Cross-Modal      â”‚                        â”‚
â”‚                      â”‚ Attention        â”‚                        â”‚
â”‚                      â”‚ Fusion           â”‚                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â”‚                                  â”‚
â”‚                               â†“                                  â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                      â”‚ Adaptive         â”‚                        â”‚
â”‚                      â”‚ Weight Learning  â”‚                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â”‚                                  â”‚
â”‚                               â†“                                  â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                      â”‚ Fused Features   â”‚                        â”‚
â”‚                      â”‚ (768-dim)        â”‚                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ORCHESTRATION                â†“                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                      â”‚ Confidence       â”‚                        â”‚
â”‚                      â”‚ Evaluator        â”‚                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â”‚                                  â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                      â”‚                  â”‚                        â”‚
â”‚             Low Confidence    High Confidence                    â”‚
â”‚                      â”‚                  â”‚                        â”‚
â”‚                      â†“                  â†“                        â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚            â”‚ RL Decision  â”‚    â”‚   Output     â”‚                 â”‚
â”‚            â”‚   Engine     â”‚    â”‚   Result     â”‚                 â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                   â”‚                                              â”‚
â”‚                   â†“                                              â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚          â”‚  Iterative   â”‚                                        â”‚
â”‚          â”‚  Refinement  â”‚                                        â”‚
â”‚          â”‚  (Loop back) â”‚                                        â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                 â”‚                                                â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚                            â†“                                     â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                   â”‚ Final Verdict    â”‚                           â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Vulnerability    â”‚
                    â”‚ Report           â”‚
                    â”‚ - Type           â”‚
                    â”‚ - Confidence     â”‚
                    â”‚ - Reasoning      â”‚
                    â”‚ - Location       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. Input Processing Layer

#### 1.1 AST Parser
```python
Location: utils/ast_parser.py
Input:    Solidity source code
Output:   Abstract Syntax Tree (AST)
Purpose:  Structure code for PDG construction
```

**Example**:
```solidity
function withdraw() { ... }
```
â†“
```json
{"type": "FunctionDefinition", "name": "withdraw", ...}
```

#### 1.2 PDG Builder
```python
Location: utils/pdg_builder.py
Input:    AST
Output:   Program Dependency Graph (PDG)
Purpose:  Capture control & data dependencies
```

**See**: [Chapter 6: PDG Explained](06-pdg-explained.md)

#### 1.3 Trace Collector
```python
Location: utils/trace_collector.py
Input:    Solidity code
Output:   Execution trace (sequence of events)
Purpose:  Capture runtime behavior
```

#### 1.4 Tokenizer
```python
Location: encoders/semantic_encoder.py
Input:    Solidity source code
Output:   Token IDs for GraphCodeBERT
Purpose:  Prepare for semantic analysis
```

---

### 2. Encoder Layer

#### 2.1 Static Encoder (GAT)
```python
Location: encoders/static_encoder.py
Architecture:
  - 3 GAT layers (multi-head attention)
  - 8 attention heads per layer
  - Edge-aware processing
Input:    PDG (graph)
Output:   768-dimensional static features
Purpose:  Detect structural patterns
```

**Key Features**:
- Graph attention mechanism
- Node feature aggregation
- Pattern recognition (reentrancy, access control, etc.)

**See**: [Chapter 4: GAT Explained](04-gat-explained.md)

#### 2.2 Dynamic Encoder (LSTM)
```python
Location: encoders/dynamic_encoder.py
Architecture:
  - 2 bidirectional LSTM layers
  - Hidden dim: 256
  - Dropout: 0.2
Input:    Execution trace (sequence)
Output:   512-dimensional dynamic features
Purpose:  Detect temporal patterns
```

**Key Features**:
- Bidirectional processing (forward + backward)
- Memory cells for context
- Sequence pattern recognition

**See**: [Chapter 5: LSTM Explained](05-lstm-explained.md)

#### 2.3 Semantic Encoder (GraphCodeBERT)
```python
Location: encoders/semantic_encoder.py
Architecture:
  - GraphCodeBERT (12 transformer layers)
  - Fine-tuned on vulnerabilities
  - Max length: 512 tokens
Input:    Tokenized source code
Output:   768-dimensional semantic features
Purpose:  Understand code semantics
```

**Key Features**:
- Pre-trained on code
- Fine-tuned on vulnerabilities
- Context-aware understanding

**See**: [Chapter 7: GraphCodeBERT Integration](07-graphcodebert.md)

---

### 3. Fusion Layer

```python
Location: fusion/cross_modal_fusion.py
Architecture:
  - Cross-modal attention
  - Adaptive weight learning
  - Feature projection
Input:    Static (768) + Dynamic (512) + Semantic (768)
Output:   Fused features (768)
Purpose:  Intelligently combine all perspectives
```

**How it Works**:

```
Step 1: Cross-Attention
  Static â†” Dynamic â†” Semantic
  (Learn which modality to focus on)

Step 2: Adaptive Weighting
  W_static  = f(confidence_static)
  W_dynamic = f(confidence_dynamic)
  W_semantic = f(confidence_semantic)

Step 3: Weighted Combination
  Fused = W_static Ã— Static +
          W_dynamic Ã— Dynamic +
          W_semantic Ã— Semantic

Step 4: Projection
  Output = MLP(Fused)
```

**See**: [Chapter 8: Cross-Modal Fusion](08-fusion-module.md)

---

### 4. Orchestration Layer

```python
Location: orchestrator/agentic_workflow.py
Components:
  - Confidence Evaluator
  - Decision Engine (RL-based)
  - Iterative Refinement Loop
Input:    Fused features + metadata
Output:   Final vulnerability report
Purpose:  Iteratively refine detection
```

**Workflow**:

```
Phase 1: Initial Analysis
  â†’ Run all encoders
  â†’ Fuse features
  â†’ Get initial prediction

Phase 2: Confidence Check
  IF confidence < threshold:
    â†’ Trigger refinement
  ELSE:
    â†’ Output result

Phase 3: Refinement (RL Decision)
  â†’ RL agent decides:
    - Which encoder to re-run?
    - Which parameters to adjust?
    - How many iterations?

Phase 4: Re-analysis
  â†’ Re-run selected encoders
  â†’ Re-fuse with updated weights
  â†’ Get refined prediction

Phase 5: Repeat
  â†’ Loop until:
    - High confidence reached, OR
    - Max iterations reached

Phase 6: Final Output
  â†’ Vulnerability type
  â†’ Confidence score
  â†’ Reasoning
  â†’ Code location
```

**See**: [Chapter 9: Agentic Orchestration](09-agentic-orchestration.md)

---

## Data Flow

### Example: Detecting Reentrancy

```
Input: Solidity contract with potential reentrancy
â”‚
â”œâ”€ Static Path (GAT)
â”‚  â”‚
â”‚  â”œâ”€ Parse to AST
â”‚  â”œâ”€ Build PDG
â”‚  â”‚   Nodes: balance, external_call, state_change
â”‚  â”‚   Edges: balanceâ†’call, callâ†’state_change
â”‚  â”‚
â”‚  â”œâ”€ GAT Processing
â”‚  â”‚   Layer 1: Learn local patterns
â”‚  â”‚   Layer 2: Learn regional patterns
â”‚  â”‚   Layer 3: Learn global patterns
â”‚  â”‚
â”‚  â””â”€ Output: [0.85, 0.02, 0.01, ...] (768-dim)
â”‚       â†‘ High reentrancy score
â”‚
â”œâ”€ Dynamic Path (LSTM)
â”‚  â”‚
â”‚  â”œâ”€ Collect execution trace
â”‚  â”‚   [SLOAD balance, CALL external, SSTORE balance]
â”‚  â”‚
â”‚  â”œâ”€ LSTM Processing
â”‚  â”‚   Forward pass: Read sequence
â”‚  â”‚   Backward pass: Context from future
â”‚  â”‚
â”‚  â””â”€ Output: [0.03, 0.89, 0.01, ...] (512-dim)
â”‚       â†‘ High temporal pattern score
â”‚
â”œâ”€ Semantic Path (GraphCodeBERT)
â”‚  â”‚
â”‚  â”œâ”€ Tokenize source code
â”‚  â”‚   ["function", "withdraw", "call", "balance", ...]
â”‚  â”‚
â”‚  â”œâ”€ GraphCodeBERT Processing
â”‚  â”‚   12 transformer layers
â”‚  â”‚   Attention over code tokens
â”‚  â”‚
â”‚  â””â”€ Output: [0.76, 0.12, 0.03, ...] (768-dim)
â”‚       â†‘ High semantic similarity to known vulnerability
â”‚
â””â”€ Fusion
   â”‚
   â”œâ”€ Cross-Attention
   â”‚   Static â†” Dynamic â†” Semantic
   â”‚   Learn: "Dynamic LSTM is most confident"
   â”‚
   â”œâ”€ Adaptive Weights
   â”‚   W_static = 0.35
   â”‚   W_dynamic = 0.45  â† Highest weight
   â”‚   W_semantic = 0.20
   â”‚
   â”œâ”€ Weighted Combination
   â”‚   Fused = 0.35 Ã— Static +
   â”‚           0.45 Ã— Dynamic +
   â”‚           0.20 Ã— Semantic
   â”‚
   â””â”€ Output: [0.82, 0.11, 0.02, ...] (768-dim)
       â†‘ Combined confidence: 82%

Orchestration
â”‚
â”œâ”€ Confidence Check
â”‚   82% < 90% threshold
â”‚   â†’ Trigger refinement
â”‚
â”œâ”€ RL Decision
â”‚   "Re-analyze with focus on static patterns"
â”‚
â”œâ”€ Refinement
â”‚   Re-run GAT with higher attention
â”‚   Re-fuse with updated weights
â”‚
â””â”€ Final Result
    Vulnerability: REENTRANCY
    Confidence: 91%
    Reasoning: "External call before state change,
                detected by all three modalities"
    Location: Line 5-7
```

---

## Why This Architecture?

### Design Principles

#### 1. **Complementary Modalities**

**Problem**: Single-view tools miss vulnerabilities

**Solution**: Three complementary views:
- **GAT**: Structure (what depends on what)
- **LSTM**: Behavior (what happens when)
- **GraphCodeBERT**: Semantics (what code means)

**Benefit**: Catch vulnerabilities missed by single-view tools

---

#### 2. **Adaptive Fusion**

**Problem**: Fixed fusion weights fail on diverse vulnerabilities

**Solution**: Learn optimal weights for each case

Example:
```
Reentrancy:   Trust LSTM more (temporal pattern)
Overflow:     Trust GAT more (structural pattern)
Bad Randomness: Trust GraphCodeBERT more (semantic pattern)
```

**Benefit**: Higher accuracy, fewer false positives

---

#### 3. **Iterative Refinement**

**Problem**: Single-pass analysis may be uncertain

**Solution**: RL agent decides when/how to refine

**Benefit**: High confidence results, efficient computation

---

#### 4. **Modular Design**

**Problem**: Monolithic tools are hard to improve

**Solution**: Separate, replaceable components

**Benefit**: Easy to upgrade individual parts

---

## Comparison with Existing Tools

### Slither (Static Only)

```
Slither:
  Input â†’ Static Analysis â†’ Output

Triton:
  Input â†’ (Static + Dynamic + Semantic) â†’ Fusion â†’ Output

Result: Triton catches temporal/semantic vulnerabilities
```

### Mythril (Dynamic Only)

```
Mythril:
  Input â†’ Symbolic Execution â†’ Output
  (Slow, limited coverage)

Triton:
  Input â†’ (Static + Dynamic + Semantic) â†’ Fusion â†’ Output
  (Fast, complete coverage)

Result: Triton is 73% faster, better coverage
```

### Securify (ML Single-Modal)

```
Securify:
  Input â†’ Single ML Model â†’ Output
  (Fixed architecture)

Triton:
  Input â†’ (GAT + LSTM + GraphCodeBERT) â†’ Fusion â†’ Output
  (Adaptive architecture)

Result: Triton has 18.6% higher F1-score
```

---

## Architecture Advantages

### âœ… Advantages

1. **Higher Accuracy** (92.5% F1 vs 78% baseline)
   - Multiple perspectives catch more vulnerabilities

2. **Lower False Positives** (40% reduction)
   - Fusion resolves conflicting signals

3. **Faster** (73% faster than Mythril)
   - Static analysis provides quick first pass
   - Dynamic only when needed

4. **Scalable**
   - Modular design
   - Can add new encoders easily

5. **Interpretable**
   - Each modality provides reasoning
   - Fusion weights show which mattered most

### âš ï¸ Limitations

1. **Training Complexity**
   - Need PDGs, traces, and labeled data
   - Multi-stage training pipeline

2. **Memory Requirements**
   - Three encoders + fusion module
   - ~2GB GPU memory per batch

3. **Dependency on External Tools**
   - Slither for PDG
   - Mythril for traces

---

## Implementation Details

### Directory Structure

```
Triton/
â”œâ”€â”€ encoders/
â”‚   â”œâ”€â”€ static_encoder.py          # GAT implementation
â”‚   â”œâ”€â”€ dynamic_encoder.py         # LSTM implementation
â”‚   â””â”€â”€ semantic_encoder.py        # GraphCodeBERT
â”‚
â”œâ”€â”€ fusion/
â”‚   â””â”€â”€ cross_modal_fusion.py      # Fusion module
â”‚
â”œâ”€â”€ orchestrator/
â”‚   â””â”€â”€ agentic_workflow.py        # RL orchestrator
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ast_parser.py              # AST parsing
â”‚   â”œâ”€â”€ pdg_builder.py             # PDG construction
â”‚   â”œâ”€â”€ trace_collector.py         # Trace collection
â”‚   â””â”€â”€ data_loader.py             # Dataset loading
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ train.py                   # Training pipeline
    â””â”€â”€ test_triton.py             # Testing script
```

### Key Classes

```python
# Static Encoder
class StaticEncoder(nn.Module)
  - pdg_to_geometric()   # Convert PDG to PyG graph
  - forward()            # GAT processing

# Dynamic Encoder
class DynamicEncoder(nn.Module)
  - forward()            # LSTM processing

# Semantic Encoder
class SemanticEncoder(nn.Module)
  - encode()             # GraphCodeBERT encoding

# Fusion Module
class CrossModalFusion(nn.Module)
  - forward()            # Multi-modal fusion

# Orchestrator
class AgenticOrchestrator
  - analyze_contract()   # Main analysis loop
  - _refine_analysis()   # Iterative refinement
```

---

## Performance Characteristics

### Time Complexity

| Component | Time Complexity | Typical Time |
|-----------|----------------|--------------|
| **PDG Construction** | O(N) | 0.5s |
| **GAT Encoding** | O(NÃ—E) | 0.8s |
| **LSTM Encoding** | O(TÂ²) | 0.6s |
| **GraphCodeBERT** | O(LÂ²) | 0.4s |
| **Fusion** | O(DÂ²) | 0.1s |
| **Orchestration** | O(KÃ—Total) | 0.3s |
| **Total** | - | **~2.3s** |

Where:
- N = number of nodes in PDG
- E = number of edges in PDG
- T = trace length
- L = code length (tokens)
- D = feature dimension
- K = refinement iterations

### Space Complexity

| Component | Space | Notes |
|-----------|-------|-------|
| **Static Encoder** | 45 MB | GAT parameters |
| **Dynamic Encoder** | 18 MB | LSTM parameters |
| **Semantic Encoder** | 475 MB | GraphCodeBERT (frozen) |
| **Fusion Module** | 12 MB | Fusion parameters |
| **Orchestrator** | 5 MB | RL agent |
| **Total** | **~555 MB** | Model size |

---

## Summary

**Triton's Architecture** combines:
- **Three encoders** (GAT, LSTM, GraphCodeBERT)
- **Intelligent fusion** (adaptive weights)
- **RL orchestration** (iterative refinement)

To achieve:
- **92.5% F1-score** (18.6% better than baseline)
- **73% faster** than dynamic-only tools
- **40% fewer false positives** than static-only tools

**Key Innovation**: Multi-modal approach with adaptive fusion and iterative refinement

---

[â† Back to Index](README.md) | [Previous: Quick Start](02-quick-start.md) | [Next: GAT Explained â†’](04-gat-explained.md)
