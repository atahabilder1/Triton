# Complete Dataset Summary

## ğŸ“Š All Dataset Locations in Your Project

You have **8 different dataset locations** with **3 main training-ready datasets**:

---

## ğŸ¯ Main Training Datasets (3)

### 1. `combined_labeled` â­ Best for Testing
**Location**: `data/datasets/combined_labeled/`
- **Total Contracts**: 228
- **Solidity Files**: 456 (train/val/test copies)
- **Size**: 3.6 MB
- **Created By**: `scripts/dataset/combine_labeled_datasets.py`
- **Sources**: SmartBugs Curated + SmartBugs Samples + SolidiFI + Not So Smart Contracts
- **Quality**: âœ… **Highest** - manually curated and validated

**Structure**:
```
combined_labeled/
â”œâ”€â”€ train/          (70% - ~160 contracts)
â”œâ”€â”€ val/            (15% - ~34 contracts)
â”œâ”€â”€ test/           (15% - ~34 contracts)
â””â”€â”€ By class directories:
    â”œâ”€â”€ access_control/         29 contracts
    â”œâ”€â”€ reentrancy/             54 contracts
    â”œâ”€â”€ safe/                   60 contracts
    â”œâ”€â”€ arithmetic/             17 contracts
    â”œâ”€â”€ unchecked_low_level_calls/ 30 contracts
    â”œâ”€â”€ bad_randomness/         10 contracts
    â”œâ”€â”€ denial_of_service/       9 contracts
    â”œâ”€â”€ time_manipulation/      11 contracts
    â”œâ”€â”€ front_running/           6 contracts
    â””â”€â”€ short_addresses/         2 contracts
```

**Pros**:
- âœ… Highest quality - manually validated
- âœ… Clean compilation - no dependencies issues
- âœ… Well-documented vulnerabilities
- âœ… Ready to use immediately

**Cons**:
- âŒ Very small - only 228 contracts
- âŒ Imbalanced - some classes have <10 samples
- âŒ Limited diversity - academic examples

**Best For**: Quick testing, pipeline validation, baseline models

---

### 2. `forge_balanced_accurate` â­ Best for Training
**Location**: `data/datasets/forge_balanced_accurate/`
- **Total Contracts**: 7,013
- **Solidity Files**: 6,575
- **Size**: 66 MB
- **Created By**: `scripts/dataset/prepare_forge_dataset_accurate.py`
- **Source**: FORGE-Artifacts with CWE â†’ vulnerability class mapping
- **Quality**: âš ï¸ **Medium** - automatic labeling

**Structure**:
```
forge_balanced_accurate/
â”œâ”€â”€ train/          (70% - 4,909 contracts)
â”‚   â”œâ”€â”€ safe/                      700 contracts
â”‚   â”œâ”€â”€ access_control/            700 contracts
â”‚   â”œâ”€â”€ arithmetic/                700 contracts
â”‚   â”œâ”€â”€ unchecked_low_level_calls/ 700 contracts
â”‚   â”œâ”€â”€ reentrancy/                560 contracts
â”‚   â”œâ”€â”€ other/                     700 contracts
â”‚   â”œâ”€â”€ denial_of_service/         350 contracts
â”‚   â”œâ”€â”€ time_manipulation/         210 contracts
â”‚   â”œâ”€â”€ front_running/             147 contracts
â”‚   â”œâ”€â”€ bad_randomness/            112 contracts
â”‚   â””â”€â”€ short_addresses/            30 contracts
â”œâ”€â”€ val/            (15% - 1,051 contracts)
â””â”€â”€ test/           (15% - 1,053 contracts)
```

**Class Distribution**:
| Class | Train | Val | Test | Total | Status |
|-------|-------|-----|------|-------|--------|
| safe | 700 | 150 | 150 | 1,000 | âœ… Well-balanced |
| access_control | 700 | 150 | 150 | 1,000 | âœ… Well-balanced |
| arithmetic | 700 | 150 | 150 | 1,000 | âœ… Well-balanced |
| unchecked_calls | 700 | 150 | 150 | 1,000 | âœ… Well-balanced |
| reentrancy | 560 | 120 | 120 | 800 | âœ… Well-balanced |
| other | 700 | 150 | 150 | 1,000 | âœ… Well-balanced |
| denial_of_service | 350 | 75 | 75 | 500 | âš ï¸ Moderate |
| time_manipulation | 210 | 45 | 45 | 300 | âš ï¸ Moderate |
| front_running | 147 | 31 | 32 | 210 | âš ï¸ Under-represented |
| bad_randomness | 112 | 24 | 24 | 160 | âŒ Under-represented |
| short_addresses | 30 | 6 | 7 | 43 | âŒ Very rare |

**Pros**:
- âœ… Large scale - 7,013 contracts
- âœ… Balanced - most classes 500-1,000 samples
- âœ… Real-world - from actual audits
- âœ… Train/val/test pre-split

**Cons**:
- âŒ Has interfaces and abstract contracts
- âŒ Missing dependencies (imports not resolved)
- âŒ Automatic labeling (CWE mapping may be noisy)
- âŒ Contains low-severity issues (code quality)
- âš ï¸ **Needs preprocessing**: flatten + validate

**Best For**: Large-scale training after preprocessing

---

### 3. `forge_filtered` â­ Filtered Version
**Location**: `data/datasets/forge_filtered/`
- **Total Contracts**: ~3,746 (estimated from train split)
- **Solidity Files**: 3,746
- **Size**: 33 MB
- **Created By**: `scripts/dataset/filter_dataset.py` (likely)
- **Source**: Filtered from forge_balanced_accurate
- **Quality**: âš ï¸ **Medium-High** - filtered subset

**Structure**:
```
forge_filtered/
â”œâ”€â”€ train/          (~2,600 contracts)
â”‚   â”œâ”€â”€ access_control/            322 contracts
â”‚   â”œâ”€â”€ arithmetic/                396 contracts
â”‚   â”œâ”€â”€ unchecked_low_level_calls/ 360 contracts
â”‚   â”œâ”€â”€ other/                     359 contracts
â”‚   â”œâ”€â”€ safe/                      333 contracts
â”‚   â”œâ”€â”€ reentrancy/                327 contracts
â”‚   â”œâ”€â”€ denial_of_service/         188 contracts
â”‚   â”œâ”€â”€ time_manipulation/         129 contracts
â”‚   â”œâ”€â”€ bad_randomness/             84 contracts
â”‚   â”œâ”€â”€ front_running/              81 contracts
â”‚   â””â”€â”€ short_addresses/            17 contracts
â”œâ”€â”€ val/
â””â”€â”€ test/
```

**Observations**:
- ğŸ“‰ ~53% smaller than forge_balanced_accurate (3,746 vs 7,013)
- ğŸ“Š Still relatively balanced across main classes
- ğŸ¤” Likely filtered to remove problematic contracts

**Pros**:
- âœ… Medium size - 3,746 contracts
- âœ… Cleaner than forge_balanced_accurate (filtered)
- âœ… More balanced than combined_labeled
- âœ… Still has good class representation

**Cons**:
- â“ No documentation on what was filtered
- â“ No summary JSON to explain filtering criteria
- âš ï¸ May still need preprocessing

**Best For**: Compromise between quality and scale

---

## ğŸ“‚ Source Datasets (5)

These are the original datasets used to create the training sets above:

### 4. `FORGE-Artifacts` (Original FORGE)
**Location**: `data/datasets/FORGE-Artifacts/`
- **Contracts**: 78,223 .sol files in `dataset/contracts/`
- **Audit Reports**: 6,454 JSON files in `dataset/results/`
- **Size**: ~1.5 GB
- **Type**: Raw audit data with CWE codes

**What's Inside**:
- Original smart contract files (with dependencies)
- Audit report JSONs with:
  - CWE codes
  - Severity levels
  - Vulnerability descriptions
  - Contract metadata (compiler version, blockchain, address)

**Best For**: Research, insights, creating custom datasets

---

### 5. `smartbugs-curated`
**Location**: `data/datasets/smartbugs-curated/`
- **Contracts**: 143 .sol files
- **Size**: 1.5 MB
- **Type**: Curated vulnerable contracts
- **Classes**: 9 vulnerability types

**Used In**: `combined_labeled` dataset

---

### 6. `smartbugs`
**Location**: `data/datasets/smartbugs/`
- **Contracts**: 50 .sol files
- **Size**: 85 MB
- **Type**: SmartBugs sample contracts

**Used In**: `combined_labeled` dataset

---

### 7. `solidifi`
**Location**: `data/datasets/solidifi/`
- **Contracts**: 50 .sol files
- **Size**: 9.7 MB
- **Type**: Safe contracts (no vulnerabilities)

**Used In**: `combined_labeled` dataset (as "safe" class)

---

### 8. `audits`
**Location**: `data/datasets/audits/`
- **Contracts**: 25 .sol files
- **Size**: 1.6 MB
- **Type**: Not So Smart Contracts

**Used In**: `combined_labeled` dataset

---

### 9. `securify`
**Location**: `data/datasets/securify/`
- **Contracts**: 381 .sol files
- **Size**: 6.4 MB
- **Type**: Securify benchmark dataset
- **Status**: â“ Not currently used in training datasets

---

## ğŸ“ˆ Dataset Comparison

| Dataset | Contracts | Size | Quality | Balance | Ready? | Best For |
|---------|-----------|------|---------|---------|--------|----------|
| **combined_labeled** | 228 | 3.6 MB | â­â­â­â­â­ | âŒ Poor | âœ… Yes | Testing |
| **forge_balanced_accurate** | 7,013 | 66 MB | â­â­â­ | âœ… Good | âš ï¸ Needs prep | Training |
| **forge_filtered** | 3,746 | 33 MB | â­â­â­â­ | âœ… Good | âš ï¸ Maybe | Compromise |
| FORGE-Artifacts | 78,223 | 1.5 GB | Raw | N/A | âŒ No | Research |
| smartbugs-curated | 143 | 1.5 MB | â­â­â­â­â­ | âŒ Poor | âœ… Yes | - |
| smartbugs | 50 | 85 MB | â­â­â­â­ | âŒ Poor | âœ… Yes | - |
| solidifi | 50 | 9.7 MB | â­â­â­â­â­ | N/A | âœ… Yes | - |
| audits | 25 | 1.6 MB | â­â­â­â­ | âŒ Poor | âœ… Yes | - |
| securify | 381 | 6.4 MB | â­â­â­ | â“ | âš ï¸ | Unused |

---

## ğŸ¯ Which Dataset Should You Use?

### Scenario 1: Quick Testing
```bash
# Use combined_labeled (228 contracts, high quality)
./start_training.sh static --train-dir data/datasets/combined_labeled/train
```
**Why**: Clean, validated, ready to use

### Scenario 2: Serious Training
```bash
# Option A: Use forge_filtered (medium size, filtered)
./verify_contracts.sh data/datasets/forge_filtered/train --max 100
./start_training.sh static --train-dir data/datasets/forge_filtered/train
```
**Why**: Good compromise - cleaner than forge_balanced_accurate

```bash
# Option B: Use forge_balanced_accurate (large, needs preprocessing)
# 1. Flatten
python scripts/dataset/flatten_contracts.py \
    data/datasets/forge_balanced_accurate/train \
    --output data/datasets/forge_flattened/train

# 2. Validate
python scripts/dataset/validate_contracts.py \
    data/datasets/forge_flattened/train \
    --output-dir data/datasets/forge_clean/train \
    --copy-valid

# 3. Verify
./verify_contracts.sh data/datasets/forge_clean/train --max 100

# 4. Train
./start_training.sh static --train-dir data/datasets/forge_clean/train
```
**Why**: Maximum scale, but requires work

### Scenario 3: Research/Analysis
```bash
# Use FORGE-Artifacts
python3 scripts/dataset/analyze_forge_audits.py \
    --forge-dir data/datasets/FORGE-Artifacts \
    --output insights.json
```
**Why**: Rich metadata, real-world insights

---

## ğŸ” Dataset Hierarchy

```
FORGE-Artifacts (78,223 contracts - Raw)
    â†“ [prepare_forge_dataset_accurate.py]
    â†“ [CWE â†’ Vulnerability mapping]
    â†“ [Balance classes]
    â†“
forge_balanced_accurate (7,013 contracts)
    â†“ [filter_dataset.py?]
    â†“ [Remove problematic contracts]
    â†“
forge_filtered (3,746 contracts)


SmartBugs + SolidiFI + Not So Smart + Audits
    â†“ [combine_labeled_datasets.py]
    â†“ [Manual curation]
    â†“
combined_labeled (228 contracts)
```

---

## ğŸ’¡ Recommendations

### 1. Start with `combined_labeled`
**Why**: Test your pipeline on clean, validated data first
```bash
./start_training.sh static --train-dir data/datasets/combined_labeled/train
```

### 2. Verify `forge_filtered`
**Why**: It's already filtered - might be ready to use!
```bash
./verify_contracts.sh data/datasets/forge_filtered/train --max 100
```
If verification shows >80% success, use it directly!

### 3. Investigate `forge_filtered`
**Why**: Understand what filtering was done
```bash
# Create summary
python3 scripts/dataset/show_dataset_summary.py data/datasets/forge_filtered

# Compare to forge_balanced_accurate
# What contracts were removed? Why?
```

### 4. Consider `securify`
**Why**: 381 contracts unused - might be valuable
```bash
# Analyze securify dataset
ls -R data/datasets/securify/
# Integrate if it has labels
```

---

## ğŸš€ Recommended Workflow

### Day 1: Quick Start
```bash
# Test on combined_labeled
./start_training.sh static --train-dir data/datasets/combined_labeled/train
```
**Goal**: Verify your training pipeline works

### Day 2: Scale Up (Option A - Easy)
```bash
# Verify forge_filtered
./verify_contracts.sh data/datasets/forge_filtered/train --max 100

# If >80% success, train directly
./start_training.sh static --train-dir data/datasets/forge_filtered/train
```
**Goal**: Train on medium-sized, filtered dataset

### Day 2: Scale Up (Option B - More Work)
```bash
# Preprocess forge_balanced_accurate
python scripts/dataset/flatten_contracts.py \
    data/datasets/forge_balanced_accurate/train \
    --output data/datasets/forge_flattened/train

python scripts/dataset/validate_contracts.py \
    data/datasets/forge_flattened/train \
    --output-dir data/datasets/forge_clean/train \
    --copy-valid

./verify_contracts.sh data/datasets/forge_clean/train --max 100
./start_training.sh static --train-dir data/datasets/forge_clean/train
```
**Goal**: Maximum training data

### Day 3: Research
```bash
# Understand FORGE insights
python3 scripts/dataset/analyze_forge_audits.py \
    --forge-dir data/datasets/FORGE-Artifacts

# Create custom filtered dataset based on insights
```

---

## ğŸ“ Summary

**Total Dataset Locations**: 8
- **3 Training-ready**: combined_labeled, forge_balanced_accurate, forge_filtered
- **5 Source datasets**: FORGE-Artifacts, smartbugs-curated, smartbugs, solidifi, audits, securify

**Total Unique Contracts**:
- **Combined_labeled**: 228 (curated, high quality)
- **Forge_filtered**: 3,746 (filtered, medium quality)
- **Forge_balanced_accurate**: 7,013 (balanced, needs preprocessing)
- **FORGE-Artifacts**: 78,223 (raw, for research)

**Recommended Path**:
1. Test: `combined_labeled` (228)
2. Train: `forge_filtered` (3,746) â† **Check this first!**
3. Scale: `forge_balanced_accurate` (7,013) after preprocessing

**Key Finding**: You have `forge_filtered` which is 53% the size of `forge_balanced_accurate` - this suggests it's already been preprocessed/filtered. **Check this dataset first** before doing more work!
